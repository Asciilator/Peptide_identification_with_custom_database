{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1078f956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base path of the project: c:\\Users\\Yusuf\\OneDrive\\LST\\Derde_jaar\\Y3Q4\\Metaproteomics_with_db\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Automatically get the base path of your project\n",
    "base_path = Path.cwd().parents[0]  # adjust .parents[0] if needed\n",
    "print(\"Base path of the project:\", base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is more robust and will work regardless of the current working directory.\n",
    "# Make sure that base_path is defined correctly.\n",
    "# Ensure the required packages are installed from the requirements.txt file\n",
    "!pip3 install -r \"{base_path}/requirements.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8be54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the path to the diamond executable and input FASTA file between the quotes below.\n",
    "diamond_exe = r\"diamond_executable_path\"\n",
    "\n",
    "# Paste the path to the input FASTA file that you want to cluster between the quotes below.\n",
    "input_fasta = r\"input_fasta_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8f901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "\n",
    "# === 1. Config ===\n",
    "diamond_exe = Path(diamond_exe)  # adjust path if needed\n",
    "input_fasta = Path(input_fasta)  # Convert to Path object for consistency\n",
    "output_dir = input_fasta.parent\n",
    "diamond_db = output_dir / \"diamond_db.dmnd\"\n",
    "\n",
    "identity_threshold = 0.95  # Set your sequence identity cutoff (0.0 to 1.0)\n",
    "cluster_output = output_dir / f\"diamond_clust{identity_threshold}_output.tsv\"\n",
    "clustered_fasta = output_dir / f\"diamond_clust{identity_threshold}_output.fasta\"\n",
    "\n",
    "# === 2. Make DIAMOND database ===\n",
    "cmd_db = [str(diamond_exe), \"makedb\", \"--in\", str(input_fasta), \"-d\", str(diamond_db)]\n",
    "print(\"Creating DIAMOND database...\")\n",
    "result = subprocess.run(cmd_db, capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(result.stderr)\n",
    "    raise RuntimeError(\"DIAMOND makedb failed.\")\n",
    "\n",
    "\n",
    "# === 3. Run DIAMOND clustering ===\n",
    "cmd_cluster = [\n",
    "    str(diamond_exe), \"linclust\",\n",
    "    \"-d\", str(diamond_db),\n",
    "    \"-o\", str(cluster_output),\n",
    "    \"--approx-id\", str(identity_threshold),\n",
    "    \"-M\", \"64G\"\n",
    "]\n",
    "\n",
    "print(f\"Running DIAMOND clustering...\\n{' '.join(cmd_cluster)}\")\n",
    "result = subprocess.run(cmd_cluster, capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    print(result.stderr)\n",
    "    raise RuntimeError(\"DIAMOND clustering failed.\")\n",
    "print(\"Clustering complete.\")\n",
    "\n",
    "# === 4. Parse clustering output ===\n",
    "df = pd.read_csv(cluster_output, sep=\"\\t\", header=None, names=[\"cluster\", \"member\"])\n",
    "cluster_map = df.groupby(\"cluster\")[\"member\"].apply(list).to_dict()\n",
    "\n",
    "# === 5. Load original sequences ===\n",
    "records_dict = {rec.id: rec for rec in SeqIO.parse(input_fasta, \"fasta\")}\n",
    "\n",
    "# === 6. Longest member becomes representative ===\n",
    "rep_records = []\n",
    "for cluster_id, members in cluster_map.items():\n",
    "    valid_members = [records_dict[m] for m in members if m in records_dict]\n",
    "    if not valid_members:\n",
    "        continue\n",
    "\n",
    "    rep_seq = max(valid_members, key=lambda r: len(r.seq))\n",
    "    rep_id = rep_seq.id\n",
    "    size = len(valid_members)\n",
    "    member_ids = [m.id for m in valid_members]\n",
    "\n",
    "    original_desc = rep_seq.description\n",
    "    new_desc = f\"{original_desc} | Cluster={rep_id} | Members={','.join(member_ids)} | Size={size}\"\n",
    "    rep_seq.description = new_desc\n",
    "    rep_seq.name = rep_id\n",
    "    rep_seq.id = rep_id\n",
    "    rep_records.append(rep_seq)\n",
    "\n",
    "# === 7. Save clustered FASTA ===\n",
    "SeqIO.write(rep_records, clustered_fasta, \"fasta\")\n",
    "print(f\"Final clustered FASTA written to:\\n{clustered_fasta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b86dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_proteins_in_fasta(fasta_path):\n",
    "    \"\"\"Count the number of protein entries in a FASTA file.\"\"\"\n",
    "    count = 0\n",
    "    with open(fasta_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\">\"):\n",
    "                count += 1\n",
    "    print(f\"Total proteins in '{fasta_path}': {count}\")\n",
    "    return count\n",
    "\n",
    "# === Example usage ===\n",
    "clustered_path = clustered_fasta\n",
    "original_path  = input_fasta\n",
    "\n",
    "# Run both\n",
    "original_count = count_proteins_in_fasta(original_path)\n",
    "clustered_count = count_proteins_in_fasta(clustered_path)\n",
    "\n",
    "# Difference\n",
    "reduction = original_count - clustered_count\n",
    "print(f\"Proteins clustered away: {reduction} ({(reduction/original_count)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e746895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "\n",
    "# === 1. Input file paths ===\n",
    "clustered_fasta_path = Path(clustered_fasta)\n",
    "unclustered_fasta_path = Path(input_fasta)\n",
    "output_fasta_path = clustered_fasta_path.with_name(clustered_fasta_path.stem + \"_with_metadata.fasta\")\n",
    "\n",
    "# === 2. Load unclustered headers (metadata) by protein ID ===\n",
    "id_to_metadata = {}\n",
    "for rec in SeqIO.parse(unclustered_fasta_path, \"fasta\"):\n",
    "    # Extract the clean ID used by clustered file (e.g., A0A679HT45)\n",
    "    # which can be extracted from headers like: >tr|A0A679HT45|...\n",
    "    parts = rec.id.split(\"|\")\n",
    "    clean_id = parts[1] if len(parts) > 2 else rec.id\n",
    "    id_to_metadata[clean_id] = rec.description\n",
    "\n",
    "# === 3. Update clustered FASTA headers with metadata ===\n",
    "updated_records = []\n",
    "for rec in SeqIO.parse(clustered_fasta_path, \"fasta\"):\n",
    "    cluster_id = rec.id\n",
    "\n",
    "    # Get metadata-rich header from original file\n",
    "    metadata_header = id_to_metadata.get(cluster_id, cluster_id)\n",
    "\n",
    "    # Extract cluster info (starts after first space)\n",
    "    cluster_info = rec.description[len(cluster_id):].strip()\n",
    "\n",
    "    # Combine metadata + cluster info\n",
    "    rec.description = f\"{metadata_header} {cluster_info}\".strip()\n",
    "    rec.name = cluster_id\n",
    "    rec.id = cluster_id\n",
    "    updated_records.append(rec)\n",
    "\n",
    "# === 4. Write updated FASTA ===\n",
    "SeqIO.write(updated_records, output_fasta_path, \"fasta\")\n",
    "print(f\"Final clustered FASTA written with full metadata:\\n{output_fasta_path}\")\n",
    "print(f\"Total sequences processed: {len(updated_records)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
